{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_line='आवेदन करने की आखिरी तारीख 31 जनवरी, 2020 है।'\n",
    "hi_words=hi_line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hi_words[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['आ', 'व', 'े', 'द', 'न'],\n",
       " ['क', 'र', 'न', 'े'],\n",
       " ['क', 'ी'],\n",
       " ['आ', 'ख', 'ि', 'र', 'ी'],\n",
       " ['त', 'ा', 'र', 'ी', 'ख'],\n",
       " ['3', '1'],\n",
       " ['ज', 'न', 'व', 'र', 'ी', ','],\n",
       " ['2', '0', '2', '0'],\n",
       " ['ह', 'ै', '।']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[c for c in w] for w in hi_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आवेदन'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आवेद\n",
      "वेदन\n"
     ]
    }
   ],
   "source": [
    "n=len(hi_line[:5])\n",
    "for i in range(n):\n",
    "    if i<n-3:\n",
    "        print(hi_line[i:i+4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: there are some english or other language words, should I remove them?\n",
    "# TODO: there are also digits, what should be done about them?\n",
    "# TODO: what about \",\",\".\",\"|\" etc, ?\n",
    "# TODO: all character gram counts can be done in one for loop\n",
    "# TODO: infact every single of the can be done with only one for loop\n",
    "# TODO: does anyone has GPU machine\n",
    "# TODO: what is the most efficient way to get syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "HI_VOWELS=['ा','ाा','ि','ी','ु','ू','े','ै','ॊ','ौ','ं',':']\n",
    "# '्'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "HI_SYLLABLES=['अ','आ','इ','ई','उ','ऊ','ए','ऐ','ओ','औ','अं','अ:','ा','ाा','ि','ी','ु','ू','े','ै','ॊ','ौ','ं',':']\n",
    "# python reads 'क:' as 'क' and ':'\n",
    "# so 'ः' --> ':'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_words.insert(0,'james')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (4293537419.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_19629/4293537419.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def get_syllables(word):\n",
    "    n=len(word)\n",
    "    word_chars=[c for c in word]\n",
    "    syllables_=[]\n",
    "    for i,c in enumerate(word_chars):\n",
    "        if c in HI_VOWELS:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syllables(word):\n",
    "    n=len(word)\n",
    "    word_chars=[c for c in word]\n",
    "    syllable_indices=[]\n",
    "    for i,c in enumerate(word_chars):\n",
    "        if c in HI_SYLLABLES:\n",
    "            syllable_indices.append(i)\n",
    "    syllable_indices_updated=[]\n",
    "    for i,index in enumerate(syllable_indices):\n",
    "        syllable_indices_updated.append([])\n",
    "    syllables_=[]\n",
    "    for i,index in enumerate(syllable_indices):\n",
    "        syllables_.append(''.join(word_chars[syllable_indices[i]:index+1]))\n",
    "    return syllables_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['आ', 'े']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_syllables(hi_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstore count data for syllables\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_unigram_count={}\n",
    "char_bigram_count={}\n",
    "char_trigram_count={}\n",
    "char_quadrigram_count={}\n",
    "\n",
    "word_unigram_count={}\n",
    "word_bigram_count={}\n",
    "word_trigram_count={}\n",
    "\n",
    "syllable_unigram_count={}\n",
    "syllable_bigram_count={}\n",
    "syllable_trigram_count={}\n",
    "\n",
    "with open('data/hi/hi.txt','r') as file:\n",
    "    for i,line in enumerate(file):\n",
    "        words=line.split()\n",
    "        s=len(words)\n",
    "        for j,word in enumerate(words):\n",
    "            \"\"\"\n",
    "            word n-gram count\n",
    "            \"\"\"\n",
    "            # unigram\n",
    "            word_unigram_count[word]=word_unigram_count.get(word,0)+1\n",
    "            # to ensure that there will be at least 3 words in each line\n",
    "            if s>2:\n",
    "                # bigram\n",
    "                if j<s-1:\n",
    "                    bi_word=' '.join(words[j:j+2])\n",
    "                    word_bigram_count[bi_word]=word_bigram_count.get(bi_word,0)+1\n",
    "                # trigram\n",
    "                if j<s-2:\n",
    "                    tri_word=' '.join(words[j:j+3])\n",
    "                    word_trigram_count[tri_word]=word_trigram_count.get(tri_word,0)+1\n",
    "            \"\"\"\n",
    "            syllable n-gram count\n",
    "            \"\"\"\n",
    "            \n",
    "            \"\"\"\n",
    "            char n-gram count\n",
    "            \"\"\"\n",
    "            n=len(word)\n",
    "            # unigram count\n",
    "            # TODO: unigram needs to be updated so that they account for that 'halant' \n",
    "            for c in word:\n",
    "                char_unigram_count[c]=char_unigram_count.get(c,0)+1\n",
    "            # bigram count\n",
    "            if n>1:\n",
    "                for i in range(n):\n",
    "                    if i<n-1:\n",
    "                        c=word[i:i+2]\n",
    "                        char_bigram_count[c]=char_bigram_count.get(c,0)+1\n",
    "            # trigram count\n",
    "            if n>2:\n",
    "                for i in range(n):\n",
    "                    if i<n-2:\n",
    "                        c=word[i:i+3]\n",
    "                        char_trigram_count[c]=char_trigram_count.get(c,0)+1\n",
    "            # quadrigram count\n",
    "            if n>3:\n",
    "                for i in range(n):\n",
    "                    if i<n-3:\n",
    "                        c=word[i:i+4]\n",
    "                        char_quadrigram_count[c]=char_quadrigram_count.get(c,0)+1\n",
    "        # print(line)\n",
    "        if i>999:\n",
    "            break\n",
    "\"\"\"\n",
    "store count data for chars\n",
    "\"\"\"\n",
    "char_unigram_count_sorted=dict(sorted(char_unigram_count.items(), key=lambda item: item[1],reverse=True))\n",
    "# print(char_unigram_count_sorted)\n",
    "with open('char_unigram_count.json','w') as file:\n",
    "    json.dump(char_unigram_count_sorted,file)\n",
    "\n",
    "char_bigram_count_sorted=dict(sorted(char_bigram_count.items(), key=lambda item: item[1],reverse=True))\n",
    "# print(char_bigram_count_sorted)\n",
    "with open('char_bigram_count.json','w') as file:\n",
    "    json.dump(char_bigram_count_sorted,file)\n",
    "\n",
    "char_trigram_count_sorted=dict(sorted(char_trigram_count.items(), key=lambda item: item[1],reverse=True))\n",
    "# print(char_trigram_count_sorted)\n",
    "with open('char_trigram_count.json','w') as file:\n",
    "    json.dump(char_trigram_count_sorted,file)\n",
    "\n",
    "char_quadrigram_count_sorted=dict(sorted(char_quadrigram_count.items(), key=lambda item: item[1],reverse=True))\n",
    "# print(char_quadrigram_count_sorted)\n",
    "with open('char_quadrigram_count.json','w') as file:\n",
    "    json.dump(char_quadrigram_count_sorted,file)\n",
    "\n",
    "\"\"\"\n",
    "store count data for words\n",
    "\"\"\"\n",
    "word_unigram_count_sorted=dict(sorted(word_unigram_count.items(), key=lambda item: item[1],reverse=True))\n",
    "# print(word_unigram_count_sorted)\n",
    "with open('word_unigram_count.json','w') as file:\n",
    "    json.dump(word_unigram_count_sorted,file)\n",
    "\n",
    "word_bigram_count_sorted=dict(sorted(word_bigram_count.items(), key=lambda item: item[1],reverse=True))\n",
    "# print(word_bigram_count_sorted)\n",
    "with open('word_bigram_count.json','w') as file:\n",
    "    json.dump(word_bigram_count_sorted,file)\n",
    "\n",
    "word_trigram_count_sorted=dict(sorted(word_trigram_count.items(), key=lambda item: item[1],reverse=True))\n",
    "# print(word_trigram_count_sorted)\n",
    "with open('word_trigram_count.json','w') as file:\n",
    "    json.dump(word_trigram_count_sorted,file)\n",
    "\n",
    "\"\"\"\n",
    "store count data for syllables\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "365d70965140afb04a698773bfdd31483bc82432b779112c2a78b5de7c16d125"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
